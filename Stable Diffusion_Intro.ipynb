{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üé® Modelos de Difus√£o: Uma Introdu√ß√£o Educativa\n",
        "\n",
        "## O que s√£o Modelos de Difus√£o?\n",
        "\n",
        "Os **modelos de difus√£o** s√£o uma das tecnologias mais revolucion√°rias da intelig√™ncia artificial para gera√ß√£o de imagens. Eles s√£o capazes de criar imagens realistas a partir de texto ou ru√≠do, e est√£o por tr√°s de ferramentas populares como DALL-E, Midjourney e Stable Diffusion.\n",
        "\n",
        "### üéØ Objetivos deste Notebook\n",
        "\n",
        "- Entender os conceitos fundamentais dos modelos de difus√£o\n",
        "- Aprender como funcionam na pr√°tica\n",
        "- Criar seu pr√≥prio modelo simples\n",
        "- Gerar imagens do zero\n",
        "\n",
        "### üìö Pr√©-requisitos\n",
        "\n",
        "- Conhecimento b√°sico de Python\n",
        "- No√ß√µes de machine learning (opcional)\n",
        "- Curiosidade e vontade de aprender!\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Conceito Fundamental: O que √© \"Difus√£o\"?\n",
        "\n",
        "Imagine que voc√™ tem uma foto n√≠tida e come√ßa a borr√°-la gradualmente at√© ela virar apenas ru√≠do. Agora, imagine que voc√™ ensina um computador a fazer o processo inverso: pegar esse ru√≠do e \"desborrar\" at√© recuperar uma imagem n√≠tida.\n",
        "\n",
        "**Isso √© exatamente o que fazem os modelos de difus√£o!**\n",
        "\n",
        "### O Processo em 3 Etapas:\n",
        "\n",
        "1. **üì∏ Adicionar Ru√≠do**: Pegamos uma imagem real e adicionamos ru√≠do gradualmente\n",
        "2. **ü§ñ Treinar o Modelo**: Ensinamos uma rede neural a \"desfazer\" esse ru√≠do\n",
        "3. **‚ú® Gerar Imagens**: Usamos o modelo treinado para criar imagens novas a partir de ru√≠do puro\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üõ†Ô∏è Configura√ß√£o do Ambiente\n",
        "\n",
        "Primeiro, vamos instalar as bibliotecas necess√°rias. Estas s√£o as ferramentas que usaremos:\n",
        "\n",
        "- **diffusers**: Biblioteca principal para modelos de difus√£o\n",
        "- **torch**: Framework de deep learning\n",
        "- **matplotlib**: Para visualizar imagens\n",
        "- **PIL**: Para manipular imagens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instala√ß√£o das bibliotecas necess√°rias\n",
        "# Execute esta c√©lula apenas uma vez\n",
        "%pip install -q diffusers torch torchvision matplotlib pillow transformers accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importa√ß√£o das bibliotecas necess√°rias\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from diffusers import DDPMScheduler, UNet2DModel, DDPMPipeline\n",
        "from torchvision import transforms\n",
        "\n",
        "# Configura√ß√£o do dispositivo (GPU se dispon√≠vel, sen√£o CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "# Fun√ß√£o para visualizar imagens\n",
        "def mostrar_imagens(imagens, titulo=\"Imagens\"):\n",
        "    \"\"\"\n",
        "    Fun√ß√£o para mostrar uma grade de imagens de forma bonita\n",
        "    \"\"\"\n",
        "    # Converte de (-1, 1) para (0, 1) para visualiza√ß√£o\n",
        "    imagens = imagens * 0.5 + 0.5\n",
        "    \n",
        "    # Cria uma grade de imagens\n",
        "    grade = torchvision.utils.make_grid(imagens, nrow=4, padding=2)\n",
        "    \n",
        "    # Converte para formato PIL para visualiza√ß√£o\n",
        "    grade_im = grade.detach().cpu().permute(1, 2, 0).clip(0, 1)\n",
        "    \n",
        "    # Mostra a imagem\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(grade_im)\n",
        "    plt.title(titulo)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "print(\"‚úÖ Bibliotecas importadas com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéØ Demonstra√ß√£o Pr√°tica: Como Funciona a Difus√£o\n",
        "\n",
        "Vamos come√ßar com um exemplo simples para entender o conceito. Vamos criar algumas imagens de exemplo e ver como o processo de adi√ß√£o de ru√≠do funciona.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar algumas imagens de exemplo para demonstrar o processo\n",
        "# Criaremos imagens simples com formas geom√©tricas\n",
        "\n",
        "def criar_imagem_exemplo(tamanho=64, tipo=\"circulo\"):\n",
        "    \"\"\"\n",
        "    Cria uma imagem de exemplo com formas simples\n",
        "    \"\"\"\n",
        "    # Cria uma imagem em branco\n",
        "    imagem = torch.zeros(3, tamanho, tamanho)\n",
        "    \n",
        "    if tipo == \"circulo\":\n",
        "        # Cria um c√≠rculo no centro\n",
        "        centro = tamanho // 2\n",
        "        raio = tamanho // 4\n",
        "        y, x = torch.meshgrid(torch.arange(tamanho), torch.arange(tamanho), indexing='ij')\n",
        "        distancia = torch.sqrt((x - centro)**2 + (y - centro)**2)\n",
        "        mascara = distancia <= raio\n",
        "        imagem[:, mascara] = 1.0  # C√≠rculo branco\n",
        "        \n",
        "    elif tipo == \"quadrado\":\n",
        "        # Cria um quadrado no centro\n",
        "        inicio = tamanho // 4\n",
        "        fim = 3 * tamanho // 4\n",
        "        imagem[:, inicio:fim, inicio:fim] = 1.0  # Quadrado branco\n",
        "        \n",
        "    elif tipo == \"triangulo\":\n",
        "        # Cria um tri√¢ngulo\n",
        "        centro = tamanho // 2\n",
        "        for i in range(tamanho // 4, 3 * tamanho // 4):\n",
        "            largura = (i - tamanho // 4) * 2\n",
        "            inicio = centro - largura // 2\n",
        "            fim = centro + largura // 2\n",
        "            if inicio >= 0 and fim < tamanho:\n",
        "                imagem[:, i, inicio:fim] = 1.0\n",
        "    \n",
        "    return imagem\n",
        "\n",
        "# Cria algumas imagens de exemplo\n",
        "imagens_exemplo = []\n",
        "tipos = [\"circulo\", \"quadrado\", \"triangulo\"]\n",
        "\n",
        "for tipo in tipos:\n",
        "    img = criar_imagem_exemplo(64, tipo)\n",
        "    imagens_exemplo.append(img)\n",
        "\n",
        "# Converte para tensor e mostra\n",
        "imagens_tensor = torch.stack(imagens_exemplo)\n",
        "mostrar_imagens(imagens_tensor, \"Imagens de Exemplo - Formas Geom√©tricas\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### üîÑ Processo de Adi√ß√£o de Ru√≠do\n",
        "\n",
        "Agora vamos ver como funciona o processo de adi√ß√£o de ru√≠do. Este √© o cora√ß√£o dos modelos de difus√£o!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos demonstrar o processo de adi√ß√£o de ru√≠do\n",
        "# Pegamos uma imagem limpa e adicionamos ru√≠do gradualmente\n",
        "\n",
        "def adicionar_ruido_simples(imagem, intensidade_ruido):\n",
        "    \"\"\"\n",
        "    Adiciona ru√≠do a uma imagem com intensidade controlada\n",
        "    intensidade_ruido: 0 = sem ru√≠do, 1 = ru√≠do total\n",
        "    \"\"\"\n",
        "    # Gera ru√≠do aleat√≥rio\n",
        "    ruido = torch.randn_like(imagem)\n",
        "    \n",
        "    # Mistura a imagem original com o ru√≠do\n",
        "    # F√≥rmula: imagem_ruidosa = (1 - intensidade) * imagem_original + intensidade * ruido\n",
        "    imagem_ruidosa = (1 - intensidade_ruido) * imagem + intensidade_ruido * ruido\n",
        "    \n",
        "    return imagem_ruidosa\n",
        "\n",
        "# Vamos pegar uma das nossas imagens de exemplo\n",
        "imagem_original = imagens_exemplo[0]  # C√≠rculo\n",
        "\n",
        "# Criar diferentes n√≠veis de ru√≠do\n",
        "intensidades = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "imagens_com_ruido = []\n",
        "\n",
        "print(\"Demonstra√ß√£o do processo de adi√ß√£o de ru√≠do:\")\n",
        "print(\"0.0 = Imagem original, 1.0 = Ru√≠do puro\")\n",
        "\n",
        "for intensidade in intensidades:\n",
        "    img_ruidosa = adicionar_ruido_simples(imagem_original, intensidade)\n",
        "    imagens_com_ruido.append(img_ruidosa)\n",
        "\n",
        "# Mostra todas as imagens em uma grade\n",
        "imagens_ruido_tensor = torch.stack(imagens_com_ruido)\n",
        "mostrar_imagens(imagens_ruido_tensor, \"Processo de Adi√ß√£o de Ru√≠do (0.0 ‚Üí 1.0)\")\n",
        "\n",
        "# Mostra tamb√©m os valores de intensidade\n",
        "for i, intensidade in enumerate(intensidades):\n",
        "    print(f\"Imagem {i+1}: Intensidade = {intensidade}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üß† Entendendo o Agendador (Scheduler)\n",
        "\n",
        "O **agendador** √© uma pe√ßa fundamental dos modelos de difus√£o. Ele controla:\n",
        "\n",
        "1. **Como adicionar ru√≠do** durante o treinamento\n",
        "2. **Como remover ru√≠do** durante a gera√ß√£o de imagens\n",
        "3. **Em que velocidade** fazer essas transforma√ß√µes\n",
        "\n",
        "Vamos criar um agendador e ver como ele funciona:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando um agendador DDPM (Denoising Diffusion Probabilistic Models)\n",
        "# Este √© um dos tipos mais comuns de agendadores\n",
        "\n",
        "agendador = DDPMScheduler(\n",
        "    num_train_timesteps=1000,  # N√∫mero de passos de ru√≠do (mais passos = mais qualidade)\n",
        "    beta_schedule=\"squaredcos_cap_v2\"  # Tipo de cronograma de ru√≠do\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Agendador criado com sucesso!\")\n",
        "print(f\"N√∫mero de passos de treinamento: {agendador.num_train_timesteps}\")\n",
        "\n",
        "# Vamos visualizar como o ru√≠do √© adicionado ao longo do tempo\n",
        "# O agendador tem par√¢metros que controlam a intensidade do ru√≠do em cada passo\n",
        "\n",
        "# Plotando a curva de ru√≠do\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# alphas_cumprod controla quanto da imagem original permanece\n",
        "plt.plot(agendador.alphas_cumprod.cpu() ** 0.5, label=\"Sinal da imagem original\", linewidth=2)\n",
        "plt.plot((1 - agendador.alphas_cumprod.cpu()) ** 0.5, label=\"Intensidade do ru√≠do\", linewidth=2)\n",
        "\n",
        "plt.xlabel(\"Passos de Ru√≠do\")\n",
        "plt.ylabel(\"Intensidade\")\n",
        "plt.title(\"Como o Ru√≠do √© Adicionado Gradualmente\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Explica√ß√£o do Gr√°fico:\")\n",
        "print(\"- Linha azul: Quanto da imagem original permanece\")\n",
        "print(\"- Linha laranja: Quanto de ru√≠do foi adicionado\")\n",
        "print(\"- No in√≠cio (passo 0): 100% imagem, 0% ru√≠do\")\n",
        "print(\"- No final (passo 1000): 0% imagem, 100% ru√≠do\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agora vamos usar o agendador para adicionar ru√≠do de forma mais sofisticada\n",
        "# Vamos pegar uma de nossas imagens e adicionar ru√≠do em diferentes passos\n",
        "\n",
        "imagem_teste = imagens_exemplo[0].unsqueeze(0)  # Adiciona dimens√£o do batch\n",
        "imagem_teste = imagem_teste.to(device)\n",
        "\n",
        "# Vamos adicionar ru√≠do em diferentes passos\n",
        "passos_teste = [0, 200, 400, 600, 800, 999]  # Diferentes n√≠veis de ru√≠do\n",
        "imagens_ruido_agendador = []\n",
        "\n",
        "print(\"Demonstra√ß√£o usando o agendador DDPM:\")\n",
        "print(\"Passos diferentes = n√≠veis diferentes de ru√≠do\")\n",
        "\n",
        "for passo in passos_teste:\n",
        "    # Cria ru√≠do aleat√≥rio\n",
        "    ruido = torch.randn_like(imagem_teste)\n",
        "    \n",
        "    # Cria tensor com o passo atual\n",
        "    timesteps = torch.tensor([passo], device=device)\n",
        "    \n",
        "    # Usa o agendador para adicionar ru√≠do\n",
        "    imagem_ruidosa = agendador.add_noise(imagem_teste, ruido, timesteps)\n",
        "    \n",
        "    imagens_ruido_agendador.append(imagem_ruidosa.squeeze(0))\n",
        "\n",
        "# Mostra as imagens\n",
        "imagens_agendador_tensor = torch.stack(imagens_ruido_agendador)\n",
        "mostrar_imagens(imagens_agendador_tensor, \"Ru√≠do Adicionado pelo Agendador DDPM\")\n",
        "\n",
        "# Mostra os passos\n",
        "for i, passo in enumerate(passos_teste):\n",
        "    print(f\"Imagem {i+1}: Passo {passo} (ru√≠do: {((1 - agendador.alphas_cumprod[passo]) ** 0.5):.3f})\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üèóÔ∏è Construindo o Modelo UNet\n",
        "\n",
        "Agora vamos criar o **modelo UNet**, que √© o \"c√©rebro\" do nosso sistema de difus√£o. O UNet √© uma rede neural especial que aprende a remover ru√≠do das imagens.\n",
        "\n",
        "### O que √© um UNet?\n",
        "\n",
        "- **U**: Tem formato de \"U\" (encolhe e depois expande)\n",
        "- **Net**: Rede neural\n",
        "- **Fun√ß√£o**: Aprende a transformar imagens ruidosas em imagens limpas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando um modelo UNet2D para nosso exemplo\n",
        "# Vamos usar um modelo pequeno para demonstra√ß√£o\n",
        "\n",
        "tamanho_imagem = 64  # Tamanho das imagens que vamos processar\n",
        "\n",
        "modelo = UNet2DModel(\n",
        "    sample_size=tamanho_imagem,        # Tamanho da imagem de entrada\n",
        "    in_channels=3,                     # 3 canais (RGB)\n",
        "    out_channels=3,                    # 3 canais de sa√≠da (RGB)\n",
        "    layers_per_block=2,                # Camadas por bloco (mais = mais complexo)\n",
        "    block_out_channels=(64, 64, 128, 128),  # Canais em cada bloco (mais = mais capacidade)\n",
        "    down_block_types=(\n",
        "        \"DownBlock2D\",                 # Blocos de redu√ß√£o (encolhem a imagem)\n",
        "        \"DownBlock2D\", \n",
        "        \"DownBlock2D\",\n",
        "        \"DownBlock2D\",\n",
        "    ),\n",
        "    up_block_types=(\n",
        "        \"UpBlock2D\",                   # Blocos de expans√£o (aumentam a imagem)\n",
        "        \"UpBlock2D\",\n",
        "        \"UpBlock2D\", \n",
        "        \"UpBlock2D\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Move o modelo para o dispositivo (GPU se dispon√≠vel)\n",
        "modelo = modelo.to(device)\n",
        "\n",
        "print(\"‚úÖ Modelo UNet criado com sucesso!\")\n",
        "print(f\"Par√¢metros do modelo: {sum(p.numel() for p in modelo.parameters()):,}\")\n",
        "\n",
        "# Vamos testar se o modelo funciona corretamente\n",
        "# Criamos uma imagem de teste com ru√≠do\n",
        "imagem_teste = torch.randn(1, 3, tamanho_imagem, tamanho_imagem).to(device)\n",
        "timestep_teste = torch.tensor([500], device=device)  # Passo intermedi√°rio\n",
        "\n",
        "# Testa o modelo\n",
        "with torch.no_grad():\n",
        "    predicao = modelo(imagem_teste, timestep_teste).sample\n",
        "\n",
        "print(f\"‚úÖ Teste do modelo bem-sucedido!\")\n",
        "print(f\"Entrada: {imagem_teste.shape}\")\n",
        "print(f\"Sa√≠da: {predicao.shape}\")\n",
        "print(\"O modelo est√° pronto para ser treinado!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéì Treinamento do Modelo\n",
        "\n",
        "Agora vamos treinar nosso modelo! O processo de treinamento √© assim:\n",
        "\n",
        "1. **Pegamos uma imagem limpa**\n",
        "2. **Adicionamos ru√≠do aleat√≥rio**\n",
        "3. **Perguntamos ao modelo**: \"Que ru√≠do foi adicionado?\"\n",
        "4. **Comparamos** a resposta do modelo com o ru√≠do real\n",
        "5. **Ajustamos** o modelo para ficar mais preciso\n",
        "\n",
        "Vamos fazer isso com nossas imagens de exemplo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparando os dados para treinamento\n",
        "# Vamos usar nossas imagens de exemplo como dataset\n",
        "\n",
        "# Converte nossas imagens para o formato correto\n",
        "dataset_treino = torch.stack(imagens_exemplo).to(device)\n",
        "print(f\"Dataset de treino: {dataset_treino.shape}\")\n",
        "\n",
        "# Configura√ß√£o do treinamento\n",
        "otimizador = torch.optim.AdamW(modelo.parameters(), lr=1e-4)  # Taxa de aprendizado\n",
        "num_epocas = 50  # N√∫mero de √©pocas (passadas completas pelos dados)\n",
        "perdas = []  # Para acompanhar o progresso\n",
        "\n",
        "print(\"üöÄ Iniciando treinamento...\")\n",
        "print(\"Isso pode levar alguns minutos...\")\n",
        "\n",
        "# Loop de treinamento\n",
        "for epoca in range(num_epocas):\n",
        "    perda_epoca = 0\n",
        "    num_batches = 0\n",
        "    \n",
        "    # Para cada imagem no nosso dataset\n",
        "    for i in range(len(dataset_treino)):\n",
        "        # Pega uma imagem limpa\n",
        "        imagem_limpa = dataset_treino[i:i+1]  # Mant√©m dimens√£o do batch\n",
        "        \n",
        "        # Gera ru√≠do aleat√≥rio\n",
        "        ruido = torch.randn_like(imagem_limpa)\n",
        "        \n",
        "        # Escolhe um passo aleat√≥rio de ru√≠do\n",
        "        timesteps = torch.randint(\n",
        "            0, agendador.num_train_timesteps, (1,), device=device\n",
        "        ).long()\n",
        "        \n",
        "        # Adiciona ru√≠do √† imagem usando o agendador\n",
        "        imagem_ruidosa = agendador.add_noise(imagem_limpa, ruido, timesteps)\n",
        "        \n",
        "        # Pergunta ao modelo: \"Que ru√≠do foi adicionado?\"\n",
        "        predicao_ruido = modelo(imagem_ruidosa, timesteps).sample\n",
        "        \n",
        "        # Calcula o erro (diferen√ßa entre ru√≠do real e predi√ß√£o)\n",
        "        perda = F.mse_loss(predicao_ruido, ruido)\n",
        "        \n",
        "        # Atualiza o modelo\n",
        "        perda.backward()\n",
        "        otimizador.step()\n",
        "        otimizador.zero_grad()\n",
        "        \n",
        "        perda_epoca += perda.item()\n",
        "        num_batches += 1\n",
        "    \n",
        "    # Calcula perda m√©dia da √©poca\n",
        "    perda_media = perda_epoca / num_batches\n",
        "    perdas.append(perda_media)\n",
        "    \n",
        "    # Mostra progresso a cada 10 √©pocas\n",
        "    if (epoca + 1) % 10 == 0:\n",
        "        print(f\"√âpoca {epoca+1}/{num_epocas}, Perda: {perda_media:.6f}\")\n",
        "\n",
        "print(\"‚úÖ Treinamento conclu√≠do!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos visualizar como o modelo aprendeu\n",
        "# Plotando a curva de perda\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Gr√°fico da perda\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(perdas, linewidth=2)\n",
        "plt.title(\"Curva de Aprendizado\")\n",
        "plt.xlabel(\"√âpoca\")\n",
        "plt.ylabel(\"Perda\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Gr√°fico da perda em escala logar√≠tmica (para ver melhor a melhoria)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(np.log(perdas), linewidth=2, color='orange')\n",
        "plt.title(\"Curva de Aprendizado (Escala Log)\")\n",
        "plt.xlabel(\"√âpoca\")\n",
        "plt.ylabel(\"Log da Perda\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä An√°lise da Curva de Aprendizado:\")\n",
        "print(f\"Perda inicial: {perdas[0]:.6f}\")\n",
        "print(f\"Perda final: {perdas[-1]:.6f}\")\n",
        "print(f\"Melhoria: {((perdas[0] - perdas[-1]) / perdas[0] * 100):.1f}%\")\n",
        "\n",
        "if perdas[-1] < perdas[0] * 0.5:\n",
        "    print(\"üéâ O modelo aprendeu bem! A perda diminuiu significativamente.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è O modelo pode precisar de mais treinamento ou ajustes.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ‚ú® Gerando Imagens Novas!\n",
        "\n",
        "Agora vem a parte mais emocionante: usar nosso modelo treinado para gerar imagens completamente novas a partir de ru√≠do puro!\n",
        "\n",
        "### Como funciona a gera√ß√£o:\n",
        "\n",
        "1. **Come√ßamos com ru√≠do puro** (imagem aleat√≥ria)\n",
        "2. **Passo a passo**, o modelo remove ru√≠do\n",
        "3. **Gradualmente**, uma imagem emerge do caos\n",
        "4. **No final**, temos uma imagem nova!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# M√©todo 1: Usando o Pipeline (mais f√°cil)\n",
        "# O pipeline combina o modelo e o agendador automaticamente\n",
        "\n",
        "pipeline = DDPMPipeline(unet=modelo, scheduler=agendador)\n",
        "pipeline = pipeline.to(device)\n",
        "\n",
        "print(\"üé® Gerando imagens com o pipeline...\")\n",
        "\n",
        "# Gera uma imagem\n",
        "resultado = pipeline()\n",
        "imagem_gerada = resultado.images[0]\n",
        "\n",
        "# Mostra a imagem gerada\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(imagem_gerada)\n",
        "plt.title(\"Imagem Gerada pelo Nosso Modelo!\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(\"üéâ Sucesso! Nossa primeira imagem gerada!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# M√©todo 2: Loop de Gera√ß√£o Manual (para entender o processo)\n",
        "# Vamos ver passo a passo como a imagem √© gerada\n",
        "\n",
        "print(\"üîç Demonstra√ß√£o do processo de gera√ß√£o passo a passo...\")\n",
        "\n",
        "# Come√ßa com ru√≠do puro\n",
        "amostra = torch.randn(1, 3, tamanho_imagem, tamanho_imagem).to(device)\n",
        "\n",
        "# Lista para armazenar os passos intermedi√°rios\n",
        "passos_intermediarios = []\n",
        "passos_para_mostrar = [0, 200, 400, 600, 800, 999]  # Passos que queremos ver\n",
        "\n",
        "# Loop de gera√ß√£o\n",
        "for i, t in enumerate(agendador.timesteps):\n",
        "    # Obt√©m a predi√ß√£o do modelo\n",
        "    with torch.no_grad():\n",
        "        predicao_ruido = modelo(amostra, t).sample\n",
        "    \n",
        "    # Atualiza a amostra removendo um pouco de ru√≠do\n",
        "    amostra = agendador.step(predicao_ruido, t, amostra).prev_sample\n",
        "    \n",
        "    # Salva alguns passos para visualiza√ß√£o\n",
        "    if i in passos_para_mostrar:\n",
        "        passos_intermediarios.append(amostra.squeeze(0).cpu())\n",
        "\n",
        "# Mostra o processo de gera√ß√£o\n",
        "print(\"Processo de gera√ß√£o do ru√≠do para imagem:\")\n",
        "imagens_processo = torch.stack(passos_intermediarios)\n",
        "mostrar_imagens(imagens_processo, \"Processo de Gera√ß√£o: Ru√≠do ‚Üí Imagem\")\n",
        "\n",
        "print(\"üéØ Explica√ß√£o:\")\n",
        "print(\"- Imagem 1: Ru√≠do puro (passo 0)\")\n",
        "print(\"- Imagem 2-5: Processo gradual de remo√ß√£o de ru√≠do\")\n",
        "print(\"- Imagem 6: Resultado final\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos gerar v√°rias imagens para ver a diversidade\n",
        "print(\"üé≤ Gerando m√∫ltiplas imagens para ver a diversidade...\")\n",
        "\n",
        "imagens_geradas = []\n",
        "num_imagens = 8\n",
        "\n",
        "for i in range(num_imagens):\n",
        "    # Gera uma nova imagem\n",
        "    resultado = pipeline()\n",
        "    imagem = resultado.images[0]\n",
        "    \n",
        "    # Converte para tensor para visualiza√ß√£o\n",
        "    imagem_tensor = torch.tensor(np.array(imagem)).permute(2, 0, 1).float() / 255.0\n",
        "    imagem_tensor = imagem_tensor * 2.0 - 1.0  # Normaliza para (-1, 1)\n",
        "    imagens_geradas.append(imagem_tensor)\n",
        "\n",
        "# Mostra todas as imagens geradas\n",
        "imagens_tensor = torch.stack(imagens_geradas)\n",
        "mostrar_imagens(imagens_tensor, \"Diversidade de Imagens Geradas\")\n",
        "\n",
        "print(\"üé® Cada imagem √© √∫nica! O modelo gera varia√ß√µes diferentes a cada vez.\")\n",
        "print(\"Isso acontece porque come√ßamos com ru√≠do aleat√≥rio diferente a cada gera√ß√£o.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üåü Aplica√ß√µes Pr√°ticas dos Modelos de Difus√£o\n",
        "\n",
        "Os modelos de difus√£o t√™m muitas aplica√ß√µes incr√≠veis no mundo real:\n",
        "\n",
        "### üé® **Arte e Design**\n",
        "- **Gera√ß√£o de arte digital**: Criar pinturas, ilustra√ß√µes e designs √∫nicos\n",
        "- **Conceito art√≠stico**: Visualizar ideias antes de criar fisicamente\n",
        "- **Estilos art√≠sticos**: Aplicar estilos de artistas famosos a novas imagens\n",
        "\n",
        "### üé¨ **Entretenimento e M√≠dia**\n",
        "- **Efeitos especiais**: Criar elementos visuais para filmes e jogos\n",
        "- **Storyboards**: Gerar esbo√ßos para anima√ß√µes e filmes\n",
        "- **Personagens**: Criar personagens √∫nicos para jogos e hist√≥rias\n",
        "\n",
        "### üèóÔ∏è **Arquitetura e Design**\n",
        "- **Visualiza√ß√£o de projetos**: Ver como ficar√° um edif√≠cio antes de construir\n",
        "- **Interior design**: Experimentar diferentes decora√ß√µes\n",
        "- **Planejamento urbano**: Visualizar cidades do futuro\n",
        "\n",
        "### üß¨ **Ci√™ncia e Pesquisa**\n",
        "- **Visualiza√ß√£o cient√≠fica**: Criar imagens para explicar conceitos complexos\n",
        "- **Simula√ß√£o de dados**: Gerar dados visuais para treinar outros modelos\n",
        "- **An√°lise m√©dica**: Ajudar na interpreta√ß√£o de exames m√©dicos\n",
        "\n",
        "### üíº **Neg√≥cios e Marketing**\n",
        "- **Publicidade**: Criar an√∫ncios e materiais promocionais\n",
        "- **Produtos**: Visualizar produtos antes da produ√ß√£o\n",
        "- **Branding**: Desenvolver identidades visuais √∫nicas\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üöÄ Pr√≥ximos Passos e Experimentos\n",
        "\n",
        "Agora que voc√™ entende os conceitos b√°sicos, aqui est√£o algumas ideias para continuar explorando:\n",
        "\n",
        "### üî¨ **Experimentos Simples**\n",
        "1. **Mude o tamanho das imagens**: Tente 32x32, 128x128, ou 256x256\n",
        "2. **Ajuste o n√∫mero de √©pocas**: Mais √©pocas = melhor qualidade (mas demora mais)\n",
        "3. **Experimente diferentes formas**: Crie imagens com estrelas, cora√ß√µes, ou outras formas\n",
        "4. **Varie a taxa de aprendizado**: Teste valores como 1e-3, 1e-5\n",
        "\n",
        "### üìö **Conceitos Avan√ßados para Explorar**\n",
        "1. **Text-to-Image**: Modelos que geram imagens a partir de descri√ß√µes em texto\n",
        "2. **Image-to-Image**: Transformar uma imagem em outra (ex: foto ‚Üí pintura)\n",
        "3. **Inpainting**: Preencher partes faltantes de uma imagem\n",
        "4. **Super-resolution**: Aumentar a resolu√ß√£o de imagens\n",
        "\n",
        "### üõ†Ô∏è **Ferramentas Recomendadas**\n",
        "- **Stable Diffusion**: Modelo popular e poderoso\n",
        "- **DALL-E**: Modelo da OpenAI\n",
        "- **Midjourney**: Ferramenta online para arte\n",
        "- **Hugging Face**: Plataforma com muitos modelos pr√©-treinados\n",
        "\n",
        "### üí° **Dicas para Melhorar**\n",
        "- **Mais dados**: Use datasets maiores para melhor qualidade\n",
        "- **Mais tempo**: Treine por mais √©pocas\n",
        "- **Arquitetura**: Experimente diferentes tipos de redes neurais\n",
        "- **Agendadores**: Teste diferentes m√©todos de adi√ß√£o/remo√ß√£o de ru√≠do\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéì Resumo do que Aprendemos\n",
        "\n",
        "Parab√©ns! Voc√™ completou uma jornada completa pelos modelos de difus√£o. Vamos revisar o que aprendemos:\n",
        "\n",
        "### üß† **Conceitos Fundamentais**\n",
        "- ‚úÖ **O que √© difus√£o**: Processo de adicionar e remover ru√≠do gradualmente\n",
        "- ‚úÖ **Agendadores**: Controlam como o ru√≠do √© adicionado e removido\n",
        "- ‚úÖ **Modelos UNet**: Redes neurais que aprendem a remover ru√≠do\n",
        "- ‚úÖ **Treinamento**: Ensinar o modelo a reconhecer e remover ru√≠do\n",
        "- ‚úÖ **Gera√ß√£o**: Criar imagens novas a partir de ru√≠do puro\n",
        "\n",
        "### üõ†Ô∏è **Habilidades Pr√°ticas**\n",
        "- ‚úÖ **Configurar ambiente**: Instalar e importar bibliotecas necess√°rias\n",
        "- ‚úÖ **Criar dados**: Gerar imagens de exemplo para treinamento\n",
        "- ‚úÖ **Treinar modelo**: Implementar loop de treinamento completo\n",
        "- ‚úÖ **Gerar imagens**: Usar modelo treinado para criar imagens novas\n",
        "- ‚úÖ **Visualizar resultados**: Mostrar o processo de gera√ß√£o passo a passo\n",
        "\n",
        "### üåü **Impacto e Aplica√ß√µes**\n",
        "- ‚úÖ **Entender aplica√ß√µes**: Arte, design, ci√™ncia, neg√≥cios\n",
        "- ‚úÖ **Conhecer ferramentas**: Stable Diffusion, DALL-E, Midjourney\n",
        "- ‚úÖ **Planejar pr√≥ximos passos**: Experimentos e conceitos avan√ßados\n",
        "\n",
        "### üéØ **O que Voc√™ Pode Fazer Agora**\n",
        "1. **Experimentar**: Modificar par√¢metros e ver os resultados\n",
        "2. **Criar**: Desenvolver seus pr√≥prios modelos de difus√£o\n",
        "3. **Aplicar**: Usar os conceitos em projetos reais\n",
        "4. **Aprender**: Explorar t√©cnicas mais avan√ßadas\n",
        "\n",
        "---\n",
        "\n",
        "## üéâ Parab√©ns!\n",
        "\n",
        "Voc√™ agora tem uma base s√≥lida em modelos de difus√£o! Esta tecnologia est√° revolucionando a forma como criamos e manipulamos imagens, e voc√™ fez parte dessa jornada.\n",
        "\n",
        "**Continue explorando, experimentando e criando!** üöÄ‚ú®\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
